---
title: 卷积网络
toc: true
date: 2018-10-05 17:05:06
tags: [卷积]
categories: [深度学习]
---

# 卷积

**m大小的输入，n大小的输出，k大小的核。**

1. 稀疏交互

   **实现：**核大小远小于输入大小。

   **作用：**减少模型的存储需求，提高统计效率。传统算法需要	$m\times n$个参数并且时间复杂度为$O(m\times n)$；稀疏交互只需要$k\times n$个参数及$O(k\times n)$的时间复杂度。

2. 参数共享

   **实现：**传统神经网络中，计算一层输出时，每一个元素的权重矩阵只会被使用到一次。在卷积神经网络中，用于一个输入的权重矩阵也会被用于其他输入。

   **作用：**只需学习一个参数集合，而不是对于每一个位置都需要学习一个单独的参数集合，降低存储需求为$k$，但是不改变前向传播的时间复杂度（$O(k\times n )$）。参数共享使得神经网络具有平移等变的性质。

3. 等变表示

   图像先做变化再卷积还是先卷积再变化，输出的结果一样。

# 池化

池化可以使输入的表示具有平移不变性。

# 卷积类型

1. 标准卷积

   同一层每个节点共享一个核。

2. 平铺卷积

3. 局部链接